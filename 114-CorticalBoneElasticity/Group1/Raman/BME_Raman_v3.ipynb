{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f9a984",
   "metadata": {},
   "source": [
    "# Raman spectra analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5c918",
   "metadata": {},
   "source": [
    "Importing necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253be4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelmin, argrelextrema\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import integrate\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcadc09",
   "metadata": {},
   "source": [
    "Your measurements should be copied to the \"data\" folder.\n",
    "Output results can be saved in \"output\" polder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eee3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = 'data/'\n",
    "out_directory = 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cf28d",
   "metadata": {},
   "source": [
    "Reading and combining all .csv files into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444855d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_files(data_directory):\n",
    "    \"\"\" Read in all data files and combine into one combined DataFrame\n",
    "    \"\"\"\n",
    "    all_data = pd.DataFrame()\n",
    "    nameit =[]\n",
    "    for f in glob.glob(os.path.join(data_directory, \"*.csv\")):\n",
    "        df = pd.read_csv(f,skiprows=(30),sep=\";\")[:-2] #first 30 and the last two rows with the metadata are removed\n",
    "        n = f.replace(data_directory,\" \") #getting the names\n",
    "        n = n.replace(\"_\", \" \")[5:-4] # replace symbols from file names \n",
    "        df.rename(columns={ df.columns[0]: n }, inplace = True)\n",
    "        all_data = pd.concat([all_data, df.T])\n",
    "        nameit.append(n)\n",
    "    all_data = all_data.astype(float)\n",
    "    all_data.columns.values.astype(float)\n",
    "    return all_data, nameit #nameit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9229f",
   "metadata": {},
   "source": [
    "Resulting dataframe contains spectral intensities from each measurement in a row-vise manner. The Raman shifts are stored as the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc3bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data, nameit = combine_files(data_directory)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51202b7",
   "metadata": {},
   "source": [
    "Creating function for the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f1da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dataframe(frame,out_directory,legendnames, filename, cutraw = False, legend = True, cut = False, show = False):\n",
    "    \"\"\" Save plot of dataframe to a specified file and location\n",
    "        cut = True to cut noisy part on the sides\n",
    "        legends collected from the file name list, too much to write on figure\n",
    "    \"\"\"\n",
    "    plot_file = os.path.join(out_directory, filename)\n",
    "    plt.ioff()         \n",
    "    fig = plt.figure(figsize=(9, 6), dpi=300)\n",
    "    shifts = frame.columns.values.astype(float)\n",
    "    for idx in range(frame.shape[0]):\n",
    "        plt.plot(shifts,frame.iloc[idx],'-',linewidth=1)\n",
    "    plt.xlabel('Shift cm$^{-1}$', fontsize=14)\n",
    "    plt.ylabel('Intensity (a.u.)', fontsize=14)\n",
    "    if legend:\n",
    "        fig.legend(legendnames, bbox_to_anchor=(0.95,0.9), facecolor=\"white\", loc=\"upper left\",fontsize=12)\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(True)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    plt.box(True)\n",
    "    if cut:\n",
    "        cut_index_start = round(frame.shape[1]*0.05)\n",
    "        cut_index_end = round(frame.shape[1]*0.9)\n",
    "        xlim = np.append(frame.columns.values[cut_index_start],frame.columns.values[cut_index_end])# left and right boundaries for x axis\n",
    "        ax.set_xlim(xlim) # set x axis boundaries\n",
    "    plt.savefig(plot_file, bbox_inches=\"tight\", dpi = 600, format='png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29929133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_dataframe(all_data,out_directory,nameit, 'RawData_All.png', show = True) # BG subtracted data plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d1ccd",
   "metadata": {},
   "source": [
    "Backgroud substraction from the whole spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3163252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subtract_BG(frame, fitorder):\n",
    "    \"\"\"BG subtraction of the chosen fitorder\n",
    "        extracts the BG based on the polynomial fit of the local minimas through the whole spectra\n",
    "    \"\"\"\n",
    "    fit_index_start = round(frame.shape[1]*0.05)\n",
    "    fit_index_end = round(frame.shape[1]*0.90)\n",
    "    shifts = pd.DataFrame(frame.columns.values[fit_index_start:fit_index_end]).astype(float).T \n",
    "    counts = pd.DataFrame(frame.values[:, fit_index_start:fit_index_end]) #gets shifts without the first noisy peak and the last long \"tail\"\n",
    "    minindex = pd.DataFrame()\n",
    "    ymin = pd.DataFrame()\n",
    "    xmin = pd.DataFrame()\n",
    "    n = 20 # number of points to be checked before and after for min counts values\n",
    "    for row in range(counts.shape[0]):\n",
    "        minindex = pd.concat([minindex, pd.DataFrame(argrelextrema(counts.values[row,:], np.less_equal, order=n)[0]).T]).reset_index(drop=True) # gives a dataframe of indexes with minimal values\n",
    "    minindex = minindex.fillna(counts.shape[1]-1) #to exclude NaN values fill in with the last index\n",
    "    for row in range(counts.shape[0]):\n",
    "        ymin = pd.concat([ymin, pd.DataFrame(counts.loc[row, minindex.values[row,:]].values).T]).reset_index(drop=True)\n",
    "        xmin = pd.concat([xmin, pd.DataFrame(shifts.loc[:, minindex.values[row,:]].values)]).reset_index(drop=True) \n",
    "    ############# Fitting BG ############\n",
    "    BGcounts = pd.DataFrame() #Background counts from linear fit\n",
    "    p = pd.DataFrame() #parameters of linear fit y = p[0]*x + p[1]\n",
    "    corrcounts = pd.DataFrame()\n",
    "    counts = pd.DataFrame(frame.values[:, fit_index_start:fit_index_end]) # [:, 210:-290] update to remove shifts from the column names and perform subtraction afterwards\n",
    "    for row in range(counts.shape[0]):\n",
    "        p = pd.concat([p, pd.DataFrame(np.polyfit(xmin.values[row,:], ymin.values[row,:], fitorder)).T]).reset_index(drop=True)\n",
    "    for row in range(counts.shape[0]):\n",
    "        BGcounts = pd.concat([BGcounts, pd.DataFrame(np.polyval(p.values[row,:], shifts.values))]).reset_index(drop=True)\n",
    "    corrcounts = counts.sub(BGcounts, fill_value=0) #subtracting BG \n",
    "    corrcounts.columns = shifts.T[0]   \n",
    "    return corrcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76384b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrcounts = subtract_BG(all_data,fitorder=2)  # BG subtraction from ALL data\n",
    "plot_dataframe(corrcounts,out_directory,nameit,'BGdata_All.png', cut = True, show = True) # BG subtracted data plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b960b",
   "metadata": {},
   "source": [
    "Supplementary functions to fit Raman bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deee44f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subtract_peakBG(peakshifts, peakcounts): \n",
    "    \"\"\" Subtract BG from peak. Does linear fit through the left and right sides of the peak and subtracts it.\n",
    "    \"\"\"\n",
    "    peak_shifts = pd.DataFrame(peakshifts).T\n",
    "    peak_counts = pd.DataFrame(peakcounts) #get shifts without the first noisy peak in df format to use .iloc \n",
    "    x_left = pd.DataFrame(peak_shifts.values[0,0:5])\n",
    "    x_right = pd.DataFrame(peak_shifts.values[0,-6:-1])\n",
    "    #x_sides = pd.concat([x_left,x_right])\n",
    "    x_sides = np.append(x_left, x_right)\n",
    "    BGcounts = pd.DataFrame()\n",
    "    p = pd.DataFrame()\n",
    "    for row in range(peak_counts.shape[0]):\n",
    "        y_left = pd.DataFrame(peak_counts.values[row,0:5])\n",
    "        y_right = pd.DataFrame(peak_counts.values[row,-6:-1])\n",
    "        y_sides = pd.concat([y_left, y_right])\n",
    "        p = pd.concat([p,pd.DataFrame(np.polyfit(x_sides, y_sides, 1)).T]).reset_index(drop=True)\n",
    "    for row in range(peak_counts.shape[0]):\n",
    "        BGcounts = pd.concat([BGcounts,pd.DataFrame(np.polyval(p.values[row,:], peak_shifts.values))]).reset_index(drop=True)\n",
    "    peak_corrcounts = peak_counts.sub(BGcounts, fill_value=0) #subtracting BG\n",
    "    peak_corrcounts.columns = peak_shifts.T[0]\n",
    "    return peak_corrcounts\n",
    "\n",
    "# we use two function types for the Raman bands fit: single and double Lorentzian\n",
    "def lorentzian(x, *p):        \n",
    "        # p = [hwhm, peak center, intensity]\n",
    "        numerator =  ( p[0]**2 )\n",
    "        denominator = ( x - (p[1]) )**2 + p[0]**2\n",
    "        y = p[2]*(numerator/denominator)\n",
    "        return y \n",
    "\n",
    "def doublelorentzian(x, *p):        \n",
    "        # p = [hwhm #1, peak center #1, intensity #1, hwhm #2, peak center #2, intensity #2]\n",
    "        numerator0 =  ( p[0]**2 )\n",
    "        denominator0 = ( x - (p[1]) )**2 + p[0]**2\n",
    "        numerator1 =  ( p[3]**2 )\n",
    "        denominator1 = ( x - (p[4]) )**2 + p[3]**2\n",
    "        y = p[2]*(numerator0/denominator0)+p[5]*(numerator1/denominator1)\n",
    "        return y \n",
    "    \n",
    "# in accordance with the fitting function, we have two functions for calculating hte fitted Raman band properties\n",
    "def peak_fit(peak_shifts, peak_corrcounts, plot = False): #if plot -> shows intermediate fittings\n",
    "    \"\"\" Lorentzian fit \n",
    "    p0 = [hwhm #1, peak center #1, intensity #1]\n",
    "    \"\"\"\n",
    "    x = peak_shifts\n",
    "    peak_pos = []\n",
    "    peak_FWHM = []\n",
    "    peak_intensity = []\n",
    "    peak_integral = pd.DataFrame()\n",
    "    for row in range(peak_corrcounts.shape[0]):\n",
    "        y = peak_corrcounts.values[row,:]\n",
    "        p0 = [2.355*np.std(x)/2.0, (max(x)+min(x))/2.0, max(y)] \n",
    "        popt, pcov = curve_fit(lorentzian, x, y, p0)\n",
    "        peak_pos = np.append(peak_pos, popt[1])\n",
    "        peak_FWHM = np.append(peak_FWHM, popt[0])\n",
    "        peak_intensity = np.append(peak_intensity, lorentzian(popt[1], *popt))  #maximum: 2.99846874275 18.3928199902\n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: lorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=300)\n",
    "            x_curve = np.linspace(min(x), max(x), 50)\n",
    "            plt.plot(x, y,'k.', fillstyle='none')\n",
    "            plt.plot(x_curve, lorentzian(x_curve, *popt), color = 'grey')\n",
    "            plt.plot(x_curve, lorentzian(x_curve, *popt), 'k.', fillstyle='none')\n",
    "            plt.show()\n",
    "    return peak_pos, peak_intensity, peak_FWHM, peak_integral\n",
    "\n",
    "def doublepeak_fit(peak_shifts, peak_corrcounts, plot = False, amideI = False, amideIII = False, v2PO4 = False): #enable plot to see each peak fitting\n",
    "    \"\"\" Double Lorentzian fit \n",
    "        p0 = [hwhm #1, peak center #1, intensity #1, hwhm #2, peak center #2, intensity #2]\n",
    "    \"\"\"\n",
    "    x = peak_shifts\n",
    "    peak_pos_left = pd.DataFrame()\n",
    "    peak_intensity_left = pd.DataFrame()\n",
    "    peak_pos_right = pd.DataFrame()\n",
    "    peak_intensity_right = pd.DataFrame()\n",
    "    peak_integral = pd.DataFrame()\n",
    "    for row in range(peak_corrcounts.shape[0]):\n",
    "        y = peak_corrcounts.values[row,:]\n",
    "        if amideI: #left shoulder~1640 cm-1, right peak~1670 cm-1\n",
    "            color = 'orange'\n",
    "            bounds = ([0, 1625, 0, 0, 1655,0], [1e6, 1650, 0.75*(max(y)), 1e6, 1680, 1e6]) # bounds for pO, for beter fitting\n",
    "            p0right, pcovright = curve_fit(lorentzian, x, y, [2.355*np.std(x)/2.0, (max(x)+min(x))/2.0, max(y)]) #use lorentzian fit for the right peak and use fitted parameters laater for double lorentzian fit\n",
    "            p0 = np.append([0.2*p0right[0], 1645, 0.1*p0right[2]], p0right) #hwhm#1 = 0.2*hwhm#2, intensity#1 = 0.1*intensity#2\n",
    "        if amideIII: #left peak ~1242 cm-1; right peak ~1272 cm-1\n",
    "            xleft = x[:len(x)//2]    #dividing array in two, to find peaks in both halfs\n",
    "            xright = x[len(x)//2:]\n",
    "            yleft = y[:len(y)//2]  \n",
    "            yright = y[len(y)//2:] \n",
    "            bounds = ([0, 1237, 0, 0, 1267,0], [1e6, 1247, 1e6, 1e6, 1277, 1e6])\n",
    "            p0 = [2.055*np.std(xleft)/2.0, 1242, max(yleft), 2.055*np.std(xright)/2.0, 1272, max(yright)] \n",
    "            color = 'tomato'\n",
    "        if v2PO4: #main peak~431 cm-1, right shoulder~450 cm-1\n",
    "            color = 'blue'\n",
    "            xleft = x[:len(x)//2]    #dividing array in two, to find peaks in both halfs\n",
    "            xright = x[len(x)//2:]\n",
    "            yleft = y[:len(y)//2]  \n",
    "            yright = y[len(y)//2:] \n",
    "            bounds = ([0, 420, 0, 0, 445,0], [1e6, 440, 1e6, 1e6, 465, 1e5]) \n",
    "            p0 = [2.055*np.std(xleft)/2.0,  431, max(yleft), 2.055*np.std(xright)/2.0,  454, max(yright)]             \n",
    "        popt, pcov = curve_fit(doublelorentzian, x, y, p0, bounds = bounds) \n",
    "        # find the peak    \n",
    "        peak_pos_left = np.append(peak_pos_left, popt[1])\n",
    "        peak_intensity_left = np.append(peak_intensity_left, doublelorentzian(popt[1], *popt))\n",
    "        peak_pos_right = np.append(peak_pos_right, popt[4])\n",
    "        peak_intensity_right = np.append(peak_intensity_right, doublelorentzian(popt[4], *popt)) \n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: doublelorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=400)\n",
    "            x_curve = np.linspace(min(x), max(x), 100)\n",
    "            plt.plot(x, y, 'k.')  \n",
    "            plt.plot(x_curve, doublelorentzian(x_curve, *popt), color = color) \n",
    "            plt.plot(popt[1], doublelorentzian(popt[1], *popt), 'k.', fillstyle='none') \n",
    "            plt.plot(popt[4], doublelorentzian(popt[4], *popt), 'k.', fillstyle='none') \n",
    "            plt.show()\n",
    "    return peak_pos_left, peak_intensity_left, peak_pos_right, peak_intensity_right, peak_integral "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35138b68",
   "metadata": {},
   "source": [
    "Analysing Raman bands of interest:\n",
    "\n",
    "### Amide I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amideI_analysis(corrcounts, directory, peak_plot = True, fit_plot = False):\n",
    "    \"\"\" peak_plot <- for plotting peak with subtracted BG\n",
    "         left shoulder~1645 cm-1, right peak~1665 cm-1\n",
    "     OUTPUT: [0] peak position of amide I left shoulder, [1] peak intensity of amide I left shoulder, \n",
    "             [2] position of amide I right peak, [3] intensity of amide I right peak\n",
    "\n",
    "    \"\"\"\n",
    "    shifts = pd.DataFrame(corrcounts.columns.values).T\n",
    "    start_index = np.where(shifts.values[0,:] == 1550.)[0][0]\n",
    "    end_index = np.where(shifts.values[0,:] == 1780.)[0][0]\n",
    "    amideI_counts = corrcounts.values[:,start_index:end_index] \n",
    "    amideI_shifts = shifts.values[0,start_index:end_index]\n",
    "    amideI_corrcounts = subtract_peakBG(amideI_shifts, amideI_counts) #subtracting BG from amideI peak\n",
    "    if peak_plot:\n",
    "        plot_dataframe(amideI_corrcounts,directory,nameit, 'BGsubtracted_amideI.png') # and plot it\n",
    "    peak_pos_left = pd.DataFrame()\n",
    "    peak_intensity_left = pd.DataFrame()\n",
    "    peak_pos_right = pd.DataFrame()\n",
    "    peak_intensity_right = pd.DataFrame()\n",
    "    peak_integral = pd.DataFrame()\n",
    "    x = amideI_shifts\n",
    "    for row in range(amideI_corrcounts.shape[0]):\n",
    "        y = amideI_corrcounts.values[row,:]\n",
    "        bounds = ([0, 1625, 0, 0, 1655,0], [1e6, 1650, 0.75*(max(y)), 1e6, 1690, 1e6]) # bounds for pO, for beter fitting\n",
    "        p0right, pcovright = curve_fit(lorentzian, x, y, [2.355*np.std(x)/2.0, (max(x)+min(x))/2.0, max(y)]) #use lorentzian fit for the right peak and use fitted parameters laater for double lorentzian fit\n",
    "        p0 = np.append([0.2*p0right[0], 1645, 0.1*p0right[2]], p0right) #hwhm#1 = 0.2*hwhm#2, intensity#1 = 0.1*intensity#2\n",
    "        popt, pcov = curve_fit(doublelorentzian, x, y, p0, bounds = bounds) \n",
    "        # find the peak    \n",
    "        peak_pos_left = np.append(peak_pos_left, popt[1])\n",
    "        peak_intensity_left = np.append(peak_intensity_left, doublelorentzian(popt[1], *popt))\n",
    "        peak_pos_right = np.append(peak_pos_right, popt[4])\n",
    "        peak_intensity_right = np.append(peak_intensity_right, doublelorentzian(popt[4], *popt)) \n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: doublelorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if fit_plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=100)\n",
    "            x_curve = np.linspace(min(x), max(x), 100)\n",
    "            plt.plot(x, y, 'k.')  #(x, y, 'k.', fillstyle='none')\n",
    "            plt.plot(x_curve, doublelorentzian(x_curve, *popt), color = 'orange') #(x_curve, *popt), 'r')\n",
    "            plt.plot(popt[1], doublelorentzian(popt[1], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.plot(popt[4], doublelorentzian(popt[4], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.show()\n",
    "    amideI_param = {'amideI_pos_left': peak_pos_left, \n",
    "                 'amideI_intensity_left': peak_intensity_left, \n",
    "                 'amideI_pos_right': peak_pos_right, \n",
    "                 'amideI_intensity_right': peak_intensity_right, \n",
    "                 'amideI_integral': peak_integral}\n",
    "    amideI_param = pd.DataFrame(data = amideI_param)\n",
    "    return(amideI_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "amideI_param = amideI_analysis(corrcounts, out_directory, fit_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a6c25",
   "metadata": {},
   "source": [
    "### Amide III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ff051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amideIII_analysis(corrcounts, src_directory, peak_plot = True, fit_plot = False):\n",
    "    \"\"\" peak_plot <- for plotting peak with subtracted BG\n",
    "             left peak ~1242 cm-1; right peak ~1272 cm-1\n",
    "         OUTPUT: [0] position of amide III left peak, [1] intensity of amide III left peak, \n",
    "                 [2] position of amide III right peak, [3] intensity of amide III right peak\n",
    "                 \n",
    "    \"\"\"     \n",
    "    shifts = pd.DataFrame(corrcounts.columns.values).T\n",
    "    start_index = np.where(shifts.values[0,:] == 1186.)[0][0]\n",
    "    end_index = np.where(shifts.values[0,:] == 1310.)[0][0]\n",
    "\n",
    "    amideIII_counts = corrcounts.values[:,start_index:end_index] \n",
    "    amideIII_shifts = shifts.values[0,start_index:end_index]\n",
    "    amideIII_corrcounts = subtract_peakBG(amideIII_shifts, amideIII_counts) #subtracting BG from amideIII peak\n",
    "    if peak_plot:\n",
    "        plot_dataframe(amideIII_corrcounts,src_directory,nameit, 'BGsubtracted_amideIII.png') # and plot it\n",
    "    peak_pos_left = pd.DataFrame()\n",
    "    peak_intensity_left = pd.DataFrame()\n",
    "    peak_pos_right = pd.DataFrame()\n",
    "    peak_intensity_right = pd.DataFrame()\n",
    "    peak_integral = pd.DataFrame()\n",
    "    x = amideIII_shifts\n",
    "    for row in range(amideIII_corrcounts.shape[0]):\n",
    "        y = amideIII_corrcounts.values[row,:]\n",
    "        xleft = x[:len(x)//2]    #dividing array in two, to find peaks in both halfs\n",
    "        xright = x[len(x)//2:]\n",
    "        yleft = y[:len(y)//2]  \n",
    "        yright = y[len(y)//2:] \n",
    "        bounds = ([0, 1237, 0, 0, 1267,0], [1e6, 1247, 1e6, 1e6, 1277, 1e6])\n",
    "        p0 = [2.055*np.std(xleft)/2.0, 1242, max(yleft), 2.055*np.std(xright)/2.0, 1272, max(yright)]     \n",
    "        popt, pcov = curve_fit(doublelorentzian, x, y, p0, bounds = bounds) \n",
    "        # find the peak    \n",
    "        peak_pos_left = np.append(peak_pos_left, popt[1])\n",
    "        peak_intensity_left = np.append(peak_intensity_left, doublelorentzian(popt[1], *popt))\n",
    "        peak_pos_right = np.append(peak_pos_right, popt[4])\n",
    "        peak_intensity_right = np.append(peak_intensity_right, doublelorentzian(popt[4], *popt)) \n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: doublelorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if fit_plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=100)\n",
    "            x_curve = np.linspace(min(x), max(x), 100)\n",
    "            plt.plot(x, y, 'k.')  #(x, y, 'k.', fillstyle='none')\n",
    "            plt.plot(x_curve, doublelorentzian(x_curve, *popt), color = 'tomato') #(x_curve, *popt), 'r')\n",
    "            plt.plot(popt[1], doublelorentzian(popt[1], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.plot(popt[4], doublelorentzian(popt[4], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.show()\n",
    "    amideIII_param = {'amideIII_pos_left': peak_pos_left, \n",
    "                 'amideIII_intensity_left': peak_intensity_left, \n",
    "                 'amideIII_pos_right': peak_pos_right, \n",
    "                 'amideIII_intensity_right': peak_intensity_right, \n",
    "                 'amideIII_integral': peak_integral}\n",
    "    amideIII_param = pd.DataFrame(data = amideIII_param)    \n",
    "    return(amideIII_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53723344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amideIII_param = amideIII_analysis(corrcounts, out_directory, fit_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4481ee3",
   "metadata": {},
   "source": [
    "### $v_1PO_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33164ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v1PO4_analysis(corrcounts, src_directory, peak_plot = True, fit_plot = False):\n",
    "    \"\"\" peak_plot <- for plotting peak with subtracted BG\n",
    "             peak ~960 cm-1           \n",
    "    \"\"\"     \n",
    "    shifts = pd.DataFrame(corrcounts.columns.values).T\n",
    "    start_index = np.where(shifts.values[0,:] == 920.)[0][0]\n",
    "    end_index = np.where(shifts.values[0,:] == 1000.)[0][0]\n",
    "    v1PO4_counts = corrcounts.values[:,start_index:end_index] \n",
    "    v1PO4_shifts = shifts.values[0,start_index:end_index]\n",
    "    v1PO4_corrcounts = subtract_peakBG(v1PO4_shifts, v1PO4_counts) #subtracting BG from  v2PO4\n",
    "    if peak_plot:\n",
    "        plot_dataframe(v1PO4_corrcounts,src_directory,nameit, 'BGsubtracted_v1PO4.png') # and plot it\n",
    "        \n",
    "    peak_pos = []\n",
    "    peak_FWHM = []\n",
    "    peak_intensity = []\n",
    "    peak_integral = pd.DataFrame()\n",
    "    x = v1PO4_shifts\n",
    "    for row in range(v1PO4_corrcounts.shape[0]):\n",
    "        y = v1PO4_corrcounts.values[row,:]\n",
    "        p0 = [2.355*np.std(x)/2.0, (max(x)+min(x))/2.0, max(y)] \n",
    "        popt, pcov = curve_fit(lorentzian, x, y, p0)\n",
    "        peak_pos = np.append(peak_pos, popt[1])\n",
    "        peak_FWHM = np.append(peak_FWHM, 2*popt[0])\n",
    "        peak_intensity = np.append(peak_intensity, lorentzian(popt[1], *popt))\n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: lorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if fit_plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=100)\n",
    "            x_curve = np.linspace(min(x), max(x), 100)\n",
    "            plt.plot(x, y,'k.', fillstyle='none')\n",
    "            plt.plot(x_curve, lorentzian(x_curve, *popt), color = 'grey')\n",
    "            plt.plot(x_curve, lorentzian(x_curve, *popt), 'k.', fillstyle='none')\n",
    "            plt.show()\n",
    "    v1PO4_param = {'v1PO4_pos': peak_pos, \n",
    "                'v1PO4_intensity': peak_intensity, \n",
    "                'v1PO4_FWHM': peak_FWHM, \n",
    "                'v1PO4_integral': peak_integral}\n",
    "    v1PO4_param = pd.DataFrame(data = v1PO4_param)\n",
    "    return(v1PO4_param)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1PO4_param = v1PO4_analysis(corrcounts, out_directory, fit_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e4dc2",
   "metadata": {},
   "source": [
    "### $v_2PO_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7844811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2PO4_analysis(corrcounts, src_directory, peak_plot = True, fit_plot = False):\n",
    "    \"\"\" peak_plot <- for plotting peak with subtracted BG\n",
    "         polar_plot <- for the polar plot of intensity vs polarization angle\n",
    "             left peak ~431 cm-1; right peak ~450 cm-1\n",
    "         OUTPUT: [0] position of v2PO4 left peak, [1] intensity of v2PO4 left peak, \n",
    "                 [2] position of v2PO4 right peak, [3] intensity of v2PO4 right peak\n",
    "                 \n",
    "    \"\"\"     \n",
    "    shifts = pd.DataFrame(corrcounts.columns.values).T\n",
    "    start_index = np.where(shifts.values[0,:] == 354.)[0][0]\n",
    "    end_index = np.where(shifts.values[0,:] == 516.)[0][0]\n",
    "    v2PO4_counts = corrcounts.values[:,start_index:end_index] \n",
    "    v2PO4_shifts = shifts.values[0,start_index:end_index]\n",
    "    v2PO4_corrcounts = subtract_peakBG(v2PO4_shifts, v2PO4_counts) #subtracting BG from  v2PO4\n",
    "    if peak_plot:\n",
    "        plot_dataframe(v2PO4_corrcounts,src_directory,nameit, 'BGsubtracted_v2PO4.png') # and plot it\n",
    "    \n",
    "    peak_pos_left = pd.DataFrame()\n",
    "    peak_intensity_left = pd.DataFrame()\n",
    "    peak_pos_right = pd.DataFrame()\n",
    "    peak_intensity_right = pd.DataFrame()\n",
    "    peak_integral = pd.DataFrame()\n",
    "    x = v2PO4_shifts\n",
    "    for row in range(v2PO4_corrcounts.shape[0]):\n",
    "        y = v2PO4_corrcounts.values[row,:]\n",
    "        xleft = x[:len(x)//2]    #dividing array in two, to find peaks in both halfs\n",
    "        xright = x[len(x)//2:]\n",
    "        yleft = y[:len(y)//2]  \n",
    "        yright = y[len(y)//2:] \n",
    "        bounds = ([0, 420, 0, 0, 445,0], [1e6, 440, 1e6, 1e6, 465, 1e5]) \n",
    "        p0 = [2.055*np.std(xleft)/2.0,  431, max(yleft), 2.055*np.std(xright)/2.0,  454, max(yright)]  \n",
    "        popt, pcov = curve_fit(doublelorentzian, x, y, p0, bounds = bounds) \n",
    "        # find the peak    \n",
    "        peak_pos_left = np.append(peak_pos_left, popt[1])\n",
    "        peak_intensity_left = np.append(peak_intensity_left, doublelorentzian(popt[1], *popt))\n",
    "        peak_pos_right = np.append(peak_pos_right, popt[4])\n",
    "        peak_intensity_right = np.append(peak_intensity_right, doublelorentzian(popt[4], *popt)) \n",
    "        peak_integral = np.append(peak_integral, integrate.quad(lambda x: doublelorentzian(x, *popt), min(x), max(x))[0])\n",
    "        if fit_plot:\n",
    "            plt.figure(figsize=(2.5, 2.5), dpi=100)\n",
    "            x_curve = np.linspace(min(x), max(x), 100)\n",
    "            plt.plot(x, y, 'k.')  #(x, y, 'k.', fillstyle='none')\n",
    "            plt.plot(x_curve, doublelorentzian(x_curve, *popt), color = 'blue') #(x_curve, *popt), 'r')\n",
    "            plt.plot(popt[1], doublelorentzian(popt[1], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.plot(popt[4], doublelorentzian(popt[4], *popt), 'k.', fillstyle='none') #(popt[1], *popt), 'k.')\n",
    "            plt.show()    \n",
    "    v2PO4_param = {'v2PO4_pos_left': peak_pos_left, \n",
    "                   'v2PO4_intensity_left': peak_intensity_left, \n",
    "                   'v2PO4_pos_right': peak_pos_right, \n",
    "                   'v2PO4_intensity_right': peak_intensity_right, \n",
    "                   'v2PO4_integral': peak_integral}\n",
    "    v2PO4_param = pd.DataFrame(data = v2PO4_param)\n",
    "    return(v2PO4_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c162a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2PO4_param = v2PO4_analysis(corrcounts, out_directory, fit_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bc0c",
   "metadata": {},
   "source": [
    "Creating matrix of Raman bands fit charachteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32229c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.concat([amideI_param, amideIII_param], axis=1)\n",
    "output_data = pd.concat([output_data, v1PO4_param], axis=1)\n",
    "output_data = pd.concat([output_data, v2PO4_param], axis=1)\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d980c",
   "metadata": {},
   "source": [
    "Calculating mineral to matrix ratio as the intergral area ratio of $\\frac{v_2PO_4}{amide III}$ \n",
    "\n",
    "and adding directly to the output dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data['M2M_ratio_v2/a3'] = output_data['v2PO4_integral']/output_data['amideIII_integral']\n",
    "output_data['M2M_ratio_v2/a3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25c553",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:red; font-family:Arial'>What are the other Raman spectral charachteristics that we can calculate from the \n",
    "   available data?</span>\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO calculate at least one more meaningful spectral characteristic\n",
    "#\n",
    "#\n",
    "#        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c43f4",
   "metadata": {},
   "source": [
    "Next are the functions for qualitative and quantitative comparison between the two samples:\n",
    "- Averaged spectra plot\n",
    "- Boxplots of chosen Raman ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba299b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotSpectra_meanSD(df_mean,df_sd,color,plot_file, zonal = True, all_sample = False):\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.ioff()\n",
    "    ax = plt.gca()\n",
    "    for i in range(df_mean.shape[0]):\n",
    "        if zonal:\n",
    "            plot_label = 'Sample '+ df_mean['Sample'][i] + ' ' + df_mean['Zone'][i]\n",
    "        if all_sample:\n",
    "            plot_label = 'Sample '+ df_mean['Sample'][i]\n",
    "        plt.plot(df_mean.iloc[i,2:], linewidth=2, color = color[i], label=plot_label) \n",
    "        plt.fill_between(df_mean.columns[2:].tolist(),\n",
    "                         df_mean.iloc[i,2:].apply(pd.to_numeric, errors='coerce') + df_sd.iloc[i,2:].apply(pd.to_numeric, errors='coerce'),\n",
    "                         df_mean.iloc[i,2:].apply(pd.to_numeric, errors='coerce') - df_sd.iloc[i,2:].apply(pd.to_numeric, errors='coerce'),\n",
    "                         color = color[i], alpha=0.3)  # Adjust transparency as needed\n",
    "    xlim = np.append(1.2*min(df_mean.columns[2:].tolist()), 0.9*max(df_mean.columns[2:].tolist())) # left and right boundaries for x axis\n",
    "    ax.set_xlim(xlim) # set x axis boundaries\n",
    "    ax.set_ylim(1.5*min(df_mean.iloc[0,2:]), 1.5*max(df_mean.iloc[0,2:])) # set x axis boundaries\n",
    "    plt.xlabel('Raman Shifts [cm-1]')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title('Averaged Spectrum with SD')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(plot_file, bbox_inches=\"tight\", dpi = 600, format='png')\n",
    "    \n",
    "    \n",
    "def boxplot(df,y_column, x_column, colors, plot_title, x_label, y_label, plot_file):\n",
    "    plt.figure(figsize=(8, 8))  # Adjust figure size as needed\n",
    "    ax = plt.gca()\n",
    "    sns.boxplot(data=df, x=x_column, y=y_column, palette=colors.values())\n",
    "    sns.swarmplot(data=df, x=x_column, y=y_column, color='black', size=10, alpha=0.8, dodge=True)\n",
    "    plt.title(plot_title, fontsize=20)\n",
    "    plt.xlabel(x_label, fontsize=16)\n",
    "    plt.ylabel(y_label, fontsize=16)\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick labels font size\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick labels font size\n",
    "    ax.set_ylim(0.8*min(df[y_column]),1.2*max(df[y_column])) # set x axis boundaries\n",
    "    plt.grid(True)\n",
    "    #p-values\n",
    "    samples = df[x_column].unique()\n",
    "    for i in range(len(samples)):\n",
    "        for j in range(i + 1, len(samples)):\n",
    "            sample1 = df[df[x_column] == samples[i]][y_column]\n",
    "            sample2 = df[df[x_column] == samples[j]][y_column]\n",
    "            p_value = ttest_ind(sample1, sample2).pvalue\n",
    "            asterisk_height = 1.1*max(max(sample1),max(sample2))+0.002*i*j # Adjust height of asterisks\n",
    "            if p_value < 0.05:\n",
    "                plt.text((i + j) / 2, 1.02*asterisk_height, 'p = '+str(np.round(p_value,3)), ha='center', va='center', fontsize=20)  # Adjust position and font size as needed\n",
    "                plt.plot([i, j], [asterisk_height, asterisk_height], color='dimgrey', lw=2)  # Add brackets\n",
    "    plt.savefig(plot_file, bbox_inches=\"tight\", dpi = 600, format='png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29575f7",
   "metadata": {},
   "source": [
    "## Batch analysis part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9403496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_name = ['1', '2'] \n",
    "sample_zone = ['haversian', 'plexiform']\n",
    "all_output_data = pd.DataFrame()\n",
    "all_spectraBG_mean = pd.DataFrame()\n",
    "all_spectraBG_SD = pd.DataFrame()\n",
    "\n",
    "sample_corrcounts = pd.DataFrame()\n",
    "sall_spectraBG_mean = pd.DataFrame()\n",
    "sall_spectraBG_SD = pd.DataFrame()\n",
    "\n",
    "for n in sample_name: \n",
    "    for z in sample_zone: \n",
    "        src_directory = data_directory +'/'+ n +'/'+ z\n",
    "        all_data, nameit = combine_files(src_directory) #combining all .csv files from src_directory in one matrix\n",
    "        corrcounts = subtract_BG(all_data,fitorder=2)  # BG subtraction from ALL data\n",
    "        sample_corrcounts = pd.concat([sample_corrcounts, corrcounts], ignore_index=True) \n",
    "        plot_dataframe(all_data,src_directory,nameit,'RawData.png') # Raw spectrs plot\n",
    "        plot_dataframe(corrcounts,src_directory,nameit,'BGdata.png',cut = True) # BG subtracted data plot\n",
    "        \n",
    "        #creating mean and SD dataframes for Zonal plots\n",
    "        corrcounts_mean = pd.DataFrame(corrcounts.mean(axis=0)).T #calculating mean spectra from the measurement group\n",
    "        corrcounts_mean.insert(0, \"Sample\", n, True)\n",
    "        corrcounts_mean.insert(1, \"Zone\", z, True)\n",
    "        corrcounts_sd = pd.DataFrame(corrcounts.std(axis=0)).T  #calculating SD of spectra from the measurement group\n",
    "        corrcounts_sd.insert(0, \"Sample\", n, True)\n",
    "        corrcounts_sd.insert(1, \"Zone\", z, True)        \n",
    "        all_spectraBG_mean = pd.concat([all_spectraBG_mean, corrcounts_mean], ignore_index=True) # combining all mean spectra into one dataframe\n",
    "        all_spectraBG_SD = pd.concat([all_spectraBG_SD, corrcounts_sd], ignore_index=True) # combining all SD of spectra into one dataframe\n",
    "\n",
    "        #Calculating Ramam ratios\n",
    "        amideI_param = amideI_analysis(corrcounts, src_directory)\n",
    "        amideIII_param = amideIII_analysis(corrcounts, src_directory)\n",
    "        v1PO4_param = v1PO4_analysis(corrcounts, src_directory)\n",
    "        v2PO4_param = v2PO4_analysis(corrcounts, src_directory)\n",
    "        output_data = pd.concat([amideI_param, amideIII_param], axis=1)\n",
    "        output_data = pd.concat([output_data, v1PO4_param], axis=1)\n",
    "        output_data = pd.concat([output_data, v2PO4_param], axis=1)\n",
    "        output_data['M2M_ratio_v2/a3'] = output_data['v2PO4_integral']/output_data['amideIII_integral']\n",
    "        \n",
    "        #TODO calculate another meaningful spectral characteristic. Add it to output data and include in the boxplots\n",
    "        \n",
    "        output_data.insert(0, \"Sample\", n, True)\n",
    "        output_data.insert(1, \"Zone\", z, True)\n",
    "        all_output_data = pd.concat([all_output_data, output_data], ignore_index=True)\n",
    "\n",
    "    \n",
    "    #Zonal analysis\n",
    "    # Plotting averaged spectra with shaded standard deviation regions for two samples\n",
    "    zonal_color = ['lightgrey','grey']\n",
    "    plotSpectra_meanSD(df_mean = all_spectraBG_mean[all_spectraBG_mean['Sample']==n].reset_index(drop=True),\n",
    "                       df_sd = all_spectraBG_SD,\n",
    "                       color = zonal_color,\n",
    "                       plot_file = os.path.join(out_directory, 'Sample-'+n+'_zonal_spectra_meanSD.png'),\n",
    "                       zonal = True)\n",
    "\n",
    "    # Boxplot of Raman ratio vs sample zone\n",
    "    boxplot(df = all_output_data[all_output_data['Sample']==n],\n",
    "                 y_column = 'M2M_ratio_v2/a3',\n",
    "                 x_column = 'Zone',            \n",
    "                 colors = {'1':zonal_color[0], \n",
    "                          '2':zonal_color[1]},          \n",
    "                 plot_title = 'Relative mineralization',\n",
    "                 x_label = 'Sample '+n,\n",
    "                 y_label = 'Mineral/Matrix (v2PO4/amide III)',\n",
    "                 plot_file = os.path.join(out_directory, n+'_MMRv2a3.png'))\n",
    "\n",
    "    #creating mean and SD dataframes for all samples analysis\n",
    "    sample_corrcounts_mean = pd.DataFrame(sample_corrcounts.mean(axis=0)).T #calculating mean spectra from the measurement group\n",
    "    sample_corrcounts_mean.insert(0, \"Sample\", n, True)\n",
    "    sample_corrcounts_mean.insert(1, \"Zone\", z, True)\n",
    "    sample_corrcounts_sd = pd.DataFrame(sample_corrcounts.std(axis=0)).T  #calculating SD of spectra from the measurement group\n",
    "    sample_corrcounts_sd.insert(0, \"Sample\", n, True)\n",
    "    sample_corrcounts_sd.insert(1, \"Zone\", z, True)        \n",
    "    sall_spectraBG_mean = pd.concat([sall_spectraBG_mean, sample_corrcounts_mean], ignore_index=True) # combining all mean spectra into one dataframe\n",
    "    sall_spectraBG_SD = pd.concat([sall_spectraBG_SD, sample_corrcounts_sd], ignore_index=True) # combining all SD of spectra into one dataframe\n",
    "\n",
    "    \n",
    "    \n",
    "# Sample comparison\n",
    "# Plot averaged spectra with shaded standard deviation regions  \n",
    "sample_colors = ['royalblue', 'tomato']\n",
    "plotSpectra_meanSD(df_mean = sall_spectraBG_mean,\n",
    "                   df_sd = sall_spectraBG_SD,\n",
    "                   color = sample_colors,\n",
    "                   plot_file = os.path.join(out_directory, 'All_samples_spectra_meanSD.png'),\n",
    "                   all_sample = True)\n",
    "\n",
    "\n",
    "# Boxplot of Raman ratio vs sample zone\n",
    "boxplot(df = all_output_data,\n",
    "             y_column = 'M2M_ratio_v2/a3',\n",
    "             x_column = 'Sample',            \n",
    "             colors = {'1':sample_colors[0], \n",
    "                      '2':sample_colors[1]},          \n",
    "             plot_title = 'Relative mineralization',\n",
    "             x_label = 'All samples',\n",
    "             y_label = 'Mineral/Matrix (v2PO4/amide III)',\n",
    "             plot_file = os.path.join(out_directory, 'Allsamples_MMRv2a3.png'))\n",
    "\n",
    "\n",
    "#saving dataframes\n",
    "all_output_data.to_csv(os.path.join(out_directory, 'Output_data.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6ba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
